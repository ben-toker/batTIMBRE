{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatLaboratory/TIMBRE/blob/main/LFP_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iz9JqoFO13E"
      },
      "source": [
        "# Run TIMBRE on real data\n",
        "\n",
        "In this notebook we import the experimental data and use LFP and spikes to predict which maze arm the rat is occupying.\n",
        "\n",
        "First, let's install TIMBRE and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Eq5x4GO1Oa"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/beatLaboratory/TIMBRE.git\n",
        "#!pip install -r requirements.txt\n",
        "#!pip install requests\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rakgNSQORDff"
      },
      "source": [
        "# Download data\n",
        "\n",
        "We will download LFP, spike, and behavioral data. We will use experimental session 4 because it is smaller and therefore faster to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poPr_-q8OvCi",
        "outputId": "d0377876-330f-43b0-aa11-8aa732e099df"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from scipy import io as iomat\n",
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import rat.helpers as helpers\n",
        "\n",
        "repository_id = \"24757638\"  # Behavior_and_spiking_data_for_rats_running_a_3-arm_maze\n",
        "url = f\"https://api.figshare.com/v2/articles/{repository_id}\"\n",
        "\n",
        "# Make the API request\n",
        "response = requests.get(url)\n",
        "files = response.json()['files']\n",
        "\n",
        "file_pattern = \"data04.mat\"\n",
        "\n",
        "# Find the matching files\n",
        "file = next((file for file in files if file['name'] == file_pattern), None)\n",
        "\n",
        "if file:\n",
        "    # Download the file using requests (previously wget, but not universal across shells)\n",
        "    download_url = file['download_url']\n",
        "    file_name = file['name']\n",
        "    print(f\"Downloading file: {file_name}\")\n",
        "    response = requests.get(download_url)\n",
        "    \n",
        "    # Load the .mat file directly from the response content\n",
        "    data = iomat.loadmat(io.BytesIO(response.content))\n",
        "\n",
        "LFPs = helpers.filter_data(data['lfps'], 2, fs=25, use_hilbert=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIMVrKy912zu"
      },
      "source": [
        "# Visualize network behavior\n",
        "\n",
        "We will train TIMBRE with different hidden layer sizes and look at the average response in each layer as a function of position along the track. We do this for the phase in which the animal is running towards the reward port while in one of the 3 maze arms. Note that for larger hidden layer sizes, the hidden nodes' responses are localized in position, even though this information is not provided to the network during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "E9zEAe2B26yb",
        "outputId": "293b2459-18f7-4fec-ffbf-009172015157"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from TIMBRE import TIMBRE\n",
        "\n",
        "fig, axs = plt.subplots(4, 4, figsize=(20, 5))\n",
        "\n",
        "trial_phase = 1\n",
        "n_folds = 5\n",
        "which_fold = 0\n",
        "\n",
        "lapID = data['lapID']\n",
        "\n",
        "test_inds, train_inds = helpers.test_train(data['lapID'], trial_phase, n_folds, which_fold)  # only test 1 fold per session\n",
        "wLFPs, _, _ = helpers.whiten(LFPs, train_inds)\n",
        "\n",
        "# Verify the shapes of the indices arrays\n",
        "print(f\"Test indices shape: {test_inds.shape}\")\n",
        "print(f\"Train indices shape: {train_inds.shape}\")\n",
        "\n",
        "# Additional debug statements to verify input to TIMBRE\n",
        "print(f\"X (wLFPs) shape: {wLFPs.shape}\")\n",
        "print(f\"Y (lapID[:, 1]) shape: {lapID[:, 1].shape}\")\n",
        "print(f\"inds_train shape: {train_inds.shape}\")\n",
        "print(f\"inds_test shape: {test_inds.shape}\")\n",
        "print(f\"X[inds_train, :] shape: {wLFPs[train_inds, :].shape}\")\n",
        "print(f\"Y[inds_train] shape: {lapID[train_inds, 1].shape}\")\n",
        "print(f\"X[inds_test, :] shape: {wLFPs[test_inds, :].shape}\")\n",
        "print(f\"Y[inds_test] shape: {lapID[test_inds, 1].shape}\")\n",
        "\n",
        "n_bins = 20\n",
        "pos_binned = helpers.group_by_pos(data['lapID'][:, 4], n_bins, train_inds)  # Convert position along the track into discrete bins.\n",
        "arm_and_pos_binned = data['lapID'][:, 1] * n_bins + pos_binned  # Represent arm x position as integer between 0-19 (arm 1), 20-39 (arm 2), 40-59 (arm 3)\n",
        "\n",
        "\n",
        "\n",
        "titles = ['Projection (real part)', 'Amplitude', 'Softmax 1', 'Softmax 2 (Output)'];\n",
        "for i in range(axs.shape[0]):\n",
        "    print(f\"Training network {i + 1} of {axs.shape[0]} (hidden layer size {3 * 2 ** i})\")  # try 4 different hidden layer sizes\n",
        "    m, _, _ = TIMBRE(wLFPs, data['lapID'][:, 1], test_inds, train_inds, hidden_nodes=3 * 2 ** i)  # train network\n",
        "    for j in range(axs.shape[1]):  # Loop through each layer\n",
        "        p = helpers.layer_output(wLFPs[test_inds], m, j)  # Calculate layer's response to input, using only test data\n",
        "        if j == 0:\n",
        "            p = p[:, :p.shape[1] // 2]  # just get real component for complex-valued output\n",
        "            axs[i, 0].set_ylabel(str(3 * 2 ** i) + ' features');\n",
        "        if i == 0:\n",
        "            axs[0, j].set_title((titles[j]));\n",
        "        axs[i, j].plot(helpers.accumarray(arm_and_pos_binned[test_inds], p));  # plot mean response of layer to test data as a function of position\n",
        "        axs[i, j].autoscale(enable=True, axis='both', tight=True);\n",
        "        if i < axs.shape[0] - 1:\n",
        "            axs[i, j].set_xticks([]);\n",
        "        else:\n",
        "            axs[i, j].set_xlabel('Position');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OvyxmIx1-NQ"
      },
      "source": [
        "# Compare TIMBRE to other models\n",
        "\n",
        "Now we will compare the performance of three classifiers:\n",
        "1.   **Carrier-based** - Linear classifier trained on the demodulated LFP. During running, the track is further subdivided into 8 bins so that the classifier can accommodate changes in place code along the maze arm.\n",
        "2.   **Carrier-free (TIMBRE)** - a complex-valued neural network for identifying phase-amplitude patterns in the LFP. We do not need to feed in the position along the track (as done with carrier-based decoding) since the hidden layer learns to tile each track without additional labels (see previous section).\n",
        "3.   **Spike-based** - Linear classifier trained on the firing rates of the neurons that were simultaneously recorded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCi4omQrhfDg",
        "outputId": "ab5dc823-89c7-4698-90fe-e5ab305efdf6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from TIMBRE import carrier_based\n",
        "\n",
        "n_folds = 5  # how many folds to split data into\n",
        "run_folds = 1  # how many folds to train (can be up to n_folds; using just 1 for speed)\n",
        "all_scores = np.zeros((3, 2, run_folds))\n",
        "\n",
        "for i in range(run_folds):\n",
        "    for j in range(all_scores.shape[1]):\n",
        "        test_inds, train_inds = helpers.test_train(data['lapID'], j + 1, n_folds, i)  # only test 1 fold per session\n",
        "        wLFPs, _, _ = helpers.whiten(LFPs, train_inds)\n",
        "        if j == 0:  # during running, subdivide track for carrier-based decoding\n",
        "            gp = helpers.group_by_pos(data['lapID'][:, 4], 8, train_inds)\n",
        "        else:\n",
        "            gp = []\n",
        "        _, _, all_scores[0, j, i] = carrier_based(wLFPs, data['lapID'][:, 1], test_inds, train_inds, subgroups=gp)\n",
        "        _, _, all_scores[1, j, i] = TIMBRE(wLFPs, data['lapID'][:, 1], test_inds, train_inds, 3 * 2 ** 3)  # 8 hidden nodes per arm\n",
        "        model_sp = LogisticRegression(max_iter=300)\n",
        "        model_sp.fit(data['spikes'][train_inds], data['lapID'][train_inds, 1])\n",
        "        all_scores[2, j, i] = np.mean(data['lapID'][test_inds, 1] == model_sp.predict(data['spikes'][test_inds]))\n",
        "\n",
        "# performance of 3 models (carrier-based, carrier-free, and spike-based) across 2 conditions (running, staying)\n",
        "print(np.mean(all_scores, axis=2))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO5CjF+uQzmFSc0hAf1GhM0",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
