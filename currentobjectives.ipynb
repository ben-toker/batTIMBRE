{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "from helpers import *\n",
    "from get_data import *\n",
    "from synchrony import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the bat data (LFP and positional data)\n",
    "#### We first need to load in the LFP data, which in this case is stored in a MATLAB file. We can do this using ```hdf5storage```. The bat's positional data is stored in a matlab file (not accessible for public use), but luckily the accessors for this data can be found in ```dataset.py``` thanks to the Yartsev Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "bat_id = '32622'\n",
    "date = '231007'\n",
    "lfp_file_path = './data/ephys/32622_231007_lfp.mat'\n",
    "\n",
    "\n",
    "#Clean up position data (remove NaNs, etc.) and load in LFP from given file path\n",
    "lfp_mat, cleaned_pos, session = load_and_clean_bat_data(data_path, bat_id, date, lfp_file_path,use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "big raw data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached aligned data from ./lfp_pos_cache/d4acd319977a5004e71a82fb97f02cb7_aligned_data.npy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m BIGRAW \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_align_lfp_and_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbat_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlfp_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/code/FRITZ/yartsev/get_data.py:48\u001b[0m, in \u001b[0;36mload_and_align_lfp_and_pos\u001b[0;34m(data_path, bat_id, date, lfp_file_path, use_cache, cache_dir)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_file):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading cached aligned data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Load LFP data from .mat file\u001b[39;00m\n\u001b[1;32m     51\u001b[0m lfp_mat \u001b[38;5;241m=\u001b[39m hdf5storage\u001b[38;5;241m.\u001b[39mloadmat(lfp_file_path)\n",
      "File \u001b[0;32m~/Desktop/code/FRITZ/yartsev/venv/lib/python3.12/site-packages/numpy/lib/npyio.py:462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load file containing pickled data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen allow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(fid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "BIGRAW = load_and_align_lfp_and_pos(data_path,bat_id,date,lfp_file_path,use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mBIGRAW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "BIGRAW.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time synchronization\n",
    "#### Before we get to the main attraction (the LFP data), we need to ensure our data is synchronized. To do this, we need to extract global timestamps from both the LFP and positional data and make sure they start at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsr = 100 #desired sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_timestamps_edges, binned_pos, pos_timestamps, lfp_indices, pos_mask = sync_and_bin_data(lfp_mat, session,cleaned_pos,fs=dsr)\n",
    "\n",
    "#lfp_timestamp_edges stores edges between timebins. this will be useful for aligning the LFP data with the position data\n",
    "#binned_pos is the cleaned position averaged over the timebins\n",
    "#pos_mask is a boolean array that marks the non-negative position timestamps\n",
    "#pos_timestamps is the cleaned and filtered timestamps of the position data\n",
    "#lfp_indices is a boolean array that marks the non-negative, decimated LFP timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of NaN values in binned_pos:\", np.isnan(binned_pos).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inside of ```lfp_timestamps_edges```, we store the *edges* between timebins. We will use this to later to bin the position data; instead of downsampling the data like we did the LFP, we will average across bins (between two edges) of the LFP timebins to get synchronized data streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First few elements of binned_pos:\\n\", binned_pos[:, :5]) # NaN values at beginning and end are expected; position is not recorded when bat is not visible.\n",
    "\n",
    "print(\"First few LFP bins:\", lfp_timestamps_edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting lfp_timestamps_edges\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lfp_timestamps_edges, label='LFP Timestamp Edges')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Timestamp (microseconds)')\n",
    "plt.title('LFP Timestamp Edges')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_timestamps_edges_trim = lfp_timestamps_edges[:-1]\n",
    "print(lfp_timestamps_edges_trim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice above that the LFP timestamp edges have N+1 the shape of the binned position. This makes sense and is expected; `lfp_timestamps_edges` contains the bins (which are stored in groups of two, i.e. the first bin is [0, 4514.4426] and so on) for which the position was binned into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben splits cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_bat_combined = extract_and_downsample_lfp_data(lfp_mat,2500,dsr,use_cache=False) #uses scipy decimate to downsample LFP\n",
    "#LFPs = filter_data(lfp_bat_combined, 1, fs=25, filt_type='high', use_hilbert=True) \n",
    "LFPs = lfp_bat_combined[lfp_indices] # mask for non-negativity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_bat_combined.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_time_diffs = np.diff(lfp_timestamps_edges)\n",
    "\n",
    "# Convert the time differences to seconds\n",
    "lfp_time_diffs_seconds = lfp_time_diffs / 1e6\n",
    "\n",
    "# Calculate the mean of the time differences in seconds\n",
    "mean_lfp_time_diff_seconds = np.mean(lfp_time_diffs_seconds)\n",
    "\n",
    "# Calculate the sampling rate\n",
    "lfp_sampling_rate = 1 / mean_lfp_time_diff_seconds\n",
    "\n",
    "print(f\"Estimated sampling rate of LFP timestamp edges: {lfp_sampling_rate} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all flights in the third cluster\n",
    "flights_cluster = session.get_flights_by_cluster((2,))\n",
    "\n",
    "# Extract all x-values from the flights\n",
    "x_values = np.concatenate([flight.filtered_position[:, 0] for flight in flights_cluster])\n",
    "x_values = x_values[~np.isnan(x_values)]\n",
    "\n",
    "# Calculate the minimum and maximum x-values\n",
    "min_x_value = np.min(x_values)\n",
    "max_x_value = np.max(x_values)\n",
    "\n",
    "# Calculate the median of the x-values\n",
    "median_x_value = np.median(x_values)\n",
    "\n",
    "# Calculate the 3% buffer based on the range of x-values\n",
    "x_range = max_x_value - min_x_value\n",
    "buffer = 0.03 * x_range\n",
    "\n",
    "# Define the range with the buffer around the median\n",
    "lower_bound = median_x_value - buffer\n",
    "upper_bound = median_x_value + buffer\n",
    "\n",
    "print(f\"Median x-value position: {median_x_value}\")\n",
    "print(f\"Buffer range: ({lower_bound}, {upper_bound})\")\n",
    "# Extract all y-values from the flights\n",
    "y_values = np.concatenate([flight.filtered_position[:, 1] for flight in flights_cluster])\n",
    "y_values = y_values[~np.isnan(y_values)]\n",
    "\n",
    "# Calculate the minimum and maximum y-values\n",
    "min_y_value = np.min(y_values)\n",
    "max_y_value = np.max(y_values)\n",
    "\n",
    "# Calculate the median of the y-values\n",
    "median_y_value = np.median(y_values)\n",
    "\n",
    "# Calculate the 3% buffer based on the range of y-values\n",
    "y_range = max_y_value - min_y_value\n",
    "buffer_y = 0.03 * y_range\n",
    "\n",
    "# Define the range with the buffer around the median\n",
    "lower_bound_y = median_y_value - buffer_y\n",
    "upper_bound_y = median_y_value + buffer_y\n",
    "\n",
    "print(f\"Median y-value position: {median_y_value}\")\n",
    "print(f\"Buffer range: ({lower_bound_y}, {upper_bound_y})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# color plots of median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Extract all flights in the second cluster\n",
    "flights_cluster = session.get_flights_by_cluster((3,))\n",
    "\n",
    "# Extract all x-values from the flights\n",
    "x_values = np.concatenate([flight.filtered_position[:, 0] for flight in flights_cluster])\n",
    "x_values = x_values[~np.isnan(x_values)]\n",
    "\n",
    "# Calculate the median of the x-values\n",
    "median_x_value = np.median(x_values)\n",
    "\n",
    "# Calculate the buffer range\n",
    "x_range = np.max(x_values) - np.min(x_values)\n",
    "buffer = 0.03 * x_range\n",
    "lower_bound = median_x_value - buffer\n",
    "upper_bound = median_x_value + buffer\n",
    "\n",
    "# Plot 3D flight paths, coloring based on the x-position relative to the median and buffer\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Colors for the regions\n",
    "left_color = 'blue'\n",
    "right_color = 'red'\n",
    "buffer_color = 'black'\n",
    "\n",
    "for flight in flights_cluster:\n",
    "    # Extract the position data\n",
    "    pos = flight.filtered_position\n",
    "    x_coords, y_coords, z_coords = pos[:, 0], pos[:, 1], pos[:, 2]\n",
    "    \n",
    "    # Clean NaN values\n",
    "    valid_mask = ~np.isnan(x_coords) & ~np.isnan(y_coords) & ~np.isnan(z_coords)\n",
    "    x_coords, y_coords, z_coords = x_coords[valid_mask], y_coords[valid_mask], z_coords[valid_mask]\n",
    "    \n",
    "    # Determine colors for each segment based on x-coordinates\n",
    "    for i in range(len(x_coords) - 1):\n",
    "        # Assign color based on the position relative to the buffer\n",
    "        if lower_bound <= x_coords[i] <= upper_bound:\n",
    "            segment_color = buffer_color\n",
    "        elif x_coords[i] < lower_bound:\n",
    "            segment_color = left_color\n",
    "        else:\n",
    "            segment_color = right_color\n",
    "        \n",
    "        # Plot the line segment with the determined color\n",
    "        ax.plot(x_coords[i:i+2], y_coords[i:i+2], z_coords[i:i+2], color=segment_color)\n",
    "\n",
    "# Set labels for each axis\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "# Set a title for the plot\n",
    "ax.set_title('Flight Paths Colored by Position Relative to Median X and Buffer')\n",
    "\n",
    "# Add a legend\n",
    "legend_handles = [\n",
    "    Line2D([0], [0], color=left_color, lw=4, label='Left of Buffer'),\n",
    "    Line2D([0], [0], color=right_color, lw=4, label='Right of Buffer'),\n",
    "    Line2D([0], [0], color=buffer_color, lw=4, label='Within Buffer'),\n",
    "    Line2D([0], [0], color='black', lw=0, marker='', markersize=0, label=f'Median X: {median_x_value:.2f}'),\n",
    "    Line2D([0], [0], color='black', lw=0, marker='', markersize=0, label=f'Buffer: Â±{buffer:.2f}')\n",
    "]\n",
    "ax.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust the view\n",
    "ax.view_init(elev=50, azim=-120)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_or_right(x, lower,upper):\n",
    "    # Classify the input x values\n",
    "    return np.where(\n",
    "        x < lower, \"left\",  # Values less than the lower buffer are \"left\"\n",
    "        np.where(x > upper, \"right\", \"within buffer\")  # Values greater than the upper buffer are \"right\"\n",
    "    )\n",
    "\n",
    "##### getting the binned position to match corresponding flights:\n",
    "flight_count =0\n",
    "flight_data = []\n",
    "cluster=2\n",
    "\n",
    "for flight in session.get_flights_by_cluster([cluster]): #marking cluster 3 flights\n",
    "    flight_count +=1\n",
    "    flight_bool, _ = get_flight_boolean_array(session,cluster,flight_count)\n",
    "\n",
    "    # Apply pos_mask (formerly valid_indices) to the flight boolean array and phase labels\n",
    "    labels = flight_bool[pos_mask]\n",
    "     # Label timebins for this flight\n",
    "    timebin_labels = label_timebins(lfp_timestamps_edges, labels, pos_timestamps, is_discrete=True)\n",
    "    \n",
    "    flight_lfp = LFPs[timebin_labels > 0] # mark LFP points which mask to specific flight in cluste\n",
    "\n",
    "     # Get binned position data for this flight\n",
    "    flight_pos = binned_pos[timebin_labels > 0]\n",
    "    \n",
    "####### Current analysis task: marking whether current x is less than or greater than x=0\n",
    "    flight_data.append(np.column_stack((\n",
    "        np.full(len(flight_pos), flight_count),\n",
    "        left_or_right(flight_pos[:,1], lower_bound_y, upper_bound_y),\n",
    "        flight_lfp\n",
    "    )))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data = np.vstack(flight_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram of each flight w/in cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_timestamps_sec = lfp_timestamps_edges_trim / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.signal import spectrogram, butter, filtfilt\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "cluster = 2\n",
    "off_samples = 500\n",
    "sampling_rate = dsr  # LFP sampling rate (Hz)\n",
    "low_pass_20hz = 20  # Low-pass filter at 20 Hz\n",
    "nperseg = 45 # Moderate segment length for better time resolution\n",
    "noverlap = nperseg // 2  # 50% overlap\n",
    "nfft = nperseg # Zero-padding for frequency interpolation\n",
    "window_type = 'hann'  # Hann window to reduce spectral leakage\n",
    "detrend_type = False # Detrend each segment\n",
    "channels_to_plot = range(120, 141, 5)  # Plot channels 80, 85, 90, 95, 100\n",
    "\n",
    "# Butterworth band-pass filter design\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data, method=\"gust\")\n",
    "\n",
    "# Iterate through all flights in cluster 2\n",
    "flight_count = 0\n",
    "cluster_flights = session.get_flights_by_cluster([cluster,])\n",
    "print(f\"Retrieved {len(cluster_flights)} flights for cluster 3.\")\n",
    "for flight in cluster_flights:  # Limit to the first three flights\n",
    "    flight_count += 1\n",
    "    \n",
    "    # Debug: Check flight metadata\n",
    "    print(f\"Processing Flight {flight_count}: Start Index {flight.timebin_start_idx}, End Index {flight.timebin_end_idx}\")\n",
    "\n",
    "    # Generate the boolean array for flight with off_samples\n",
    "    flight_bool, phase_labels = get_flight_boolean_array(session, cluster, flight_count, off_samples)\n",
    "\n",
    "    # Apply valid_indices to the flight boolean array\n",
    "    labels = flight_bool[pos_mask]\n",
    "    valid_phase_labels = phase_labels[pos_mask]\n",
    "\n",
    "    # Label timebins for this flight\n",
    "    timebin_labels = label_timebins(lfp_timestamps_edges, labels, pos_timestamps, is_discrete=True)\n",
    "    \n",
    "    # Debug: Check unique timebin labels\n",
    "    print(f\"Unique timebin labels for Flight {flight_count}: {np.unique(timebin_labels)}\")\n",
    "\n",
    "    # Adjust valid_phase_labels to match timebin_labels\n",
    "    adjusted_phase_labels = label_timebins(lfp_timestamps_edges, valid_phase_labels, pos_timestamps, is_discrete=True)\n",
    "    flight_phases = adjusted_phase_labels[timebin_labels > 0]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Get LFP data for this flight\n",
    "    flight_lfp = LFPs[timebin_labels > 0]\n",
    "    \n",
    "    flight_pos = binned_pos[timebin_labels > 0]\n",
    "\n",
    "    # Check if data exists and process each channel\n",
    "    if flight_lfp.size > 0:\n",
    "        print(f\"Flight {flight_count}: Flight LFP shape: {flight_lfp.shape}\")\n",
    "\n",
    "        # Ensure the signal has the expected number of channels\n",
    "        if flight_lfp.ndim == 2 and flight_lfp.shape[1] >= 192:\n",
    "            for channel in channels_to_plot:\n",
    "                if channel >= flight_lfp.shape[1]:\n",
    "                    print(f\"Skipping channel {channel} for Flight {flight_count}: Channel out of range.\")\n",
    "                    continue\n",
    "\n",
    "                channel_data = flight_lfp[:, channel]  # Select the specific channel\n",
    "\n",
    "                # Apply low-pass filter\n",
    "                channel_data = bandpass_filter(channel_data, 0.1, low_pass_20hz, sampling_rate)\n",
    "                \n",
    "                # Plot the filtered signal for debugging\n",
    "                plt.figure(figsize=(10, 4))\n",
    "                plt.plot(lfp_timestamps_edges_trim[timebin_labels > 0] / 1e6, channel_data)\n",
    "                plt.title(f\"Filtered Signal: Flight {flight_count}, Channel {channel} (Lowpass 20 Hz)\")\n",
    "                plt.xlabel(\"Sample Index\")\n",
    "                plt.ylabel(\"Amplitude\")\n",
    "                plt.show()\n",
    "\n",
    "                # Compute the spectrogram\n",
    "                f, t, Sxx = spectrogram(\n",
    "                    channel_data,\n",
    "                    fs=sampling_rate,\n",
    "                    window=window_type,\n",
    "                    nperseg=nperseg,\n",
    "                    noverlap=noverlap,\n",
    "                    nfft=nfft,\n",
    "                    detrend=detrend_type,\n",
    "                    scaling='spectrum',\n",
    "                    mode='psd'\n",
    "                )\n",
    "\n",
    "                # Skip plotting if the spectrogram is empty\n",
    "                if np.all(Sxx == 0) or np.all(np.isnan(Sxx)) or np.max(Sxx) < 1e-10:\n",
    "                    print(f\"Flight {flight_count}, Channel {channel}: Empty or invalid spectrogram. Skipping plot.\")\n",
    "                    continue\n",
    "\n",
    "                # Plot the spectrogram below 20 Hz\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.pcolormesh(\n",
    "                    t, f, Sxx,\n",
    "                    shading=\"auto\",\n",
    "                    cmap=\"inferno\",  # Black -> Red -> Yellow -> White\n",
    "                )\n",
    "                #plt.axvline(flight_start_time, color=\"red\", linestyle=\"--\", label=\"Flight Start\")\n",
    "                #plt.axvline(flight_end_time, color=\"red\", linestyle=\"--\", label=\"Flight End\")\n",
    "                plt.colorbar(label=\"Power (dB)\")\n",
    "                plt.title(f\"Spectrogram of Flight {flight_count}, Channel {channel} (Bandpassed {low_pass_20hz} Hz)\")\n",
    "                plt.xlabel(\"Time (s)\")\n",
    "                plt.ylabel(\"Frequency (Hz)\")\n",
    "                plt.ylim(0, 50)  # Focus on frequencies below 20 Hz\n",
    "                plt.show()\n",
    "                \n",
    "                # Plot the flight position\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(flight_pos[:, 0], flight_pos[:, 1], label='Flight Position')\n",
    "                plt.title(f\"Flight {flight_count} Position\")\n",
    "                plt.xlabel(\"X Position\")\n",
    "                plt.ylabel(\"Y Position\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "        else:\n",
    "            print(f\"Flight {flight_count}: Insufficient channels. Skipping.\")\n",
    "    else:\n",
    "        print(f\"Flight {flight_count}: No LFP data found. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training TIMBRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\"left\": 0, \"right\": 1}\n",
    "classifications = flight_data[:,1]\n",
    "# Assuming flight_data[:, 2] is a 2D array of strings\n",
    "# Convert all elements to complex numbers while preserving the original shape\n",
    "lfp_data = np.array([np.array([complex(val) for val in row]) for row in flight_data[:, 2:]])\n",
    "\n",
    "# Map the labels to integers\n",
    "Y = np.array([label_mapping[label] for label in classifications if label != \"within buffer\"])  # Exclude buffer range\n",
    "\n",
    "# Extract the LFP data corresponding to non-\"0\" labels\n",
    "X = lfp_data[classifications != \"within buffer\"]  # Use rows where the labels aren't \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of categorical labels\n",
    "unique, counts = np.unique(Y, return_counts=True)\n",
    "total = len(Y)\n",
    "distribution = {label: (count / total) * 100 for label, count in zip(unique, counts)}\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from TIMBRE import TIMBRE\n",
    "\n",
    "k = 3 # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "hidden_nodes=3\n",
    "learn_rate=0.1\n",
    "is_categorical=True\n",
    "\n",
    "# Assuming X and Y are your data and labels\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(f\"Train indices: {train_index}\")\n",
    "    print(f\"Test indices: {test_index}\")\n",
    "\n",
    "    # Use train_index and test_index to index into X and Y\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Call TIMBRE or other model with the current fold's train-test split\n",
    "    model, fitted_model, test_acc = TIMBRE(\n",
    "        X=X,\n",
    "        Y=Y,\n",
    "        inds_test=test_index,\n",
    "        inds_train=train_index,\n",
    "        hidden_nodes=hidden_nodes,\n",
    "        learn_rate=learn_rate,\n",
    "        is_categorical=is_categorical,\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    print(f\"Fold {fold + 1} Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot accuracy and loss from fittedModel\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot training vs. validation accuracy\n",
    "axs[0].plot(fitted_model.history['accuracy'], label='Train')\n",
    "axs[0].plot(fitted_model.history['val_accuracy'], label='Test')\n",
    "axs[0].set_title('Accuracy')\n",
    "axs[0].set_xlabel('Training epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot training vs. validation loss\n",
    "axs[1].plot(fitted_model.history['loss'], label='Train')\n",
    "axs[1].plot(fitted_model.history['val_loss'], label='Test')\n",
    "axs[1].set_title('Loss')\n",
    "axs[1].set_xlabel('Training epoch')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split indices into training and testing sets\n",
    "inds_train, inds_test = train_test_split(np.arange(len(X)), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TIMBRE import TIMBRE\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for TIMBRE\n",
    "hidden_node_sizes = [3, 10, 30]  # Hidden node sizes to test\n",
    "learn_rate = 0.001\n",
    "is_categorical = True\n",
    "iterations = 3  # Number of iterations per hidden node size\n",
    "\n",
    "# Store results\n",
    "results = {size: [] for size in hidden_node_sizes}\n",
    "\n",
    "# Loop over hidden node sizes and iterations\n",
    "for hidden_nodes in hidden_node_sizes:\n",
    "    for iteration in range(iterations):\n",
    "        print(f\"Testing hidden_nodes={hidden_nodes}, iteration={iteration + 1}\")\n",
    "\n",
    "        # Call TIMBRE\n",
    "        model, fitted_model, test_acc = TIMBRE(\n",
    "            X=X,\n",
    "            Y=Y,\n",
    "            inds_test=inds_test,\n",
    "            inds_train=inds_train,\n",
    "            hidden_nodes=hidden_nodes,\n",
    "            learn_rate=learn_rate,\n",
    "            is_categorical=is_categorical,\n",
    "            verbosity=0  # Suppress detailed output for cleaner logs\n",
    "        )\n",
    "\n",
    "        # Store test accuracy\n",
    "        results[hidden_nodes].append(test_acc)\n",
    "        print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "        # Plot accuracy and loss from fittedModel\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        # Plot training vs. validation accuracy\n",
    "        axs[0].plot(fitted_model.history['accuracy'], label='Train')\n",
    "        axs[0].plot(fitted_model.history['val_accuracy'], label='Test')\n",
    "        axs[0].set_title('Accuracy')\n",
    "        axs[0].set_xlabel('Training epoch')\n",
    "        axs[0].legend()\n",
    "\n",
    "        # Plot training vs. validation loss\n",
    "        axs[1].plot(fitted_model.history['loss'], label='Train')\n",
    "        axs[1].plot(fitted_model.history['val_loss'], label='Test')\n",
    "        axs[1].set_title('Loss')\n",
    "        axs[1].set_xlabel('Training epoch')\n",
    "        axs[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Calculate average accuracy for each hidden node size\n",
    "average_accuracies = {size: np.mean(accs) for size, accs in results.items()}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nResults:\")\n",
    "for size, accs in results.items():\n",
    "    print(f\"Hidden Nodes: {size}, Accuracies: {accs}, Average Accuracy: {average_accuracies[size]}\")\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "hidden_sizes = list(average_accuracies.keys())\n",
    "average_accs = list(average_accuracies.values())\n",
    "\n",
    "ax.bar(hidden_sizes, average_accs, color='skyblue')\n",
    "ax.set_title(\"Average Test Accuracy vs Hidden Node Size\")\n",
    "ax.set_xlabel(\"Hidden Node Size\")\n",
    "ax.set_ylabel(\"Average Test Accuracy\")\n",
    "plt.xticks(hidden_sizes)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
