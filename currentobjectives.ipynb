{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import hdf5storage\n",
    "from helpers import *\n",
    "from get_data import *\n",
    "from synchrony import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the bat data (LFP and positional data)\n",
    "#### We first need to load in the LFP data, which in this case is stored in a MATLAB file. We can do this using ```hdf5storage```. The bat's positional data is stored in a matlab file (not accessible for public use), but luckily the accessors for this data can be found in ```dataset.py``` thanks to the Yartsev Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure of lfp_data: <class 'numpy.ndarray'>, (1, 2)\n",
      "Loading Flight Room | 32622 | 231007 from cache...\n",
      "Positional data shape: (841160, 3)\n",
      "Cleaned positional data shape: (841160, 3)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data'\n",
    "bat_id = '32622'\n",
    "date = '231007'\n",
    "lfp_file_path = './data/ephys/32622_231007_lfp.mat'\n",
    "\n",
    "\n",
    "#Clean up position data (remove NaNs, etc.) and load in LFP from given file path\n",
    "lfp_mat, cleaned_pos, session = load_and_clean_bat_data(data_path, bat_id, date, lfp_file_path,use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time synchronization\n",
    "#### Before we get to the main attraction (the LFP data), we need to ensure our data is synchronized. To do this, we need to extract global timestamps from both the LFP and positional data and make sure they start at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFP timestamps structure: (17222917, 1)\n",
      "Decimated LFP timestamps shape: (172230,)\n",
      "LFP timestamp edges shape: (170691,)\n",
      "Positional timestamp diff (microseconds): [8333.33333331 8333.33333334 8333.33333334 ... 8333.33772278 8333.33771515\n",
      " 8333.33771515]\n",
      "Cleaned positional data shape: (824435, 3)\n",
      "Binned positional data shape: (170690, 3)\n"
     ]
    }
   ],
   "source": [
    "lfp_timestamps_edges, binned_pos, pos_timestamps, lfp_indices, pos_mask = sync_and_bin_data(lfp_mat, session,cleaned_pos)\n",
    "\n",
    "#lfp_timestamp_edges stores edges between timebins. this will be useful for aligning the LFP data with the position data\n",
    "#binned_pos is the cleaned position averaged over the timebins\n",
    "#pos_mask is a boolean array that marks the non-negative position timestamps\n",
    "#pos_timestamps is the cleaned and filtered timestamps of the position data\n",
    "#lfp_indices is a boolean array that marks the non-negative, decimated LFP timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in binned_pos: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaN values in binned_pos:\", np.isnan(binned_pos).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inside of ```lfp_timestamps_edges```, we store the *edges* between timebins. We will use this to later to bin the position data; instead of downsampling the data like we did the LFP, we will average across bins (between two edges) of the LFP timebins to get synchronized data streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of binned_pos:\n",
      " [[        nan         nan         nan]\n",
      " [-1.35497956 -1.70192085  0.01016301]\n",
      " [-1.35496366 -1.70190326  0.01020436]\n",
      " ...\n",
      " [-1.24507387 -1.627617    0.04300965]\n",
      " [-1.24505479 -1.62760721  0.0430833 ]\n",
      " [        nan         nan         nan]]\n",
      "First few LFP bins: [     0.           4514.44262606  44057.00577409  83599.56892214\n",
      " 123142.1320702 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"First few elements of binned_pos:\\n\", binned_pos[:, :5]) # NaN values at beginning and end are expected; position is not recorded when bat is not visible.\n",
    "\n",
    "print(\"First few LFP bins:\", lfp_timestamps_edges[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice above that the LFP timestamp edges have N+1 the shape of the binned position. This makes sense and is expected; `lfp_timestamps_edges` contains the bins (which are stored in groups of two, i.e. the first bin is [0, 4514.4426] and so on) for which the position was binned into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben splits cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_or_right(x):\n",
    "    # Use numpy's vectorized operations to determine the labels\n",
    "    result = np.empty_like(x, dtype=object)  # Create an array to hold the results\n",
    "    result[x > 0] = \"right\"  # Assign \"right\" where x > 0\n",
    "    result[x == 0] = \"0\"     # Assign \"0\" where x == 0\n",
    "    result[x < 0] = \"left\"   # Assign \"left\" where x < 0\n",
    "    return result\n",
    "\n",
    "\n",
    "##### getting the binned position to match corresponding flights:\n",
    "flight_count =0\n",
    "for flight in session.get_flights_by_cluster([3]): #marking cluster 3 flights\n",
    "    flight_count +=1\n",
    "    flight_bool, phase_labels, _ = get_flight_boolean_array(session,flight_count)\n",
    "\n",
    "    # Apply pos_mask (formerly valid_indices) to the flight boolean array and phase labels\n",
    "    labels = flight_bool[pos_mask]\n",
    "    valid_phase_labels = phase_labels[pos_mask] \n",
    "\n",
    "     # Label timebins for this flight\n",
    "    timebin_labels = label_timebins(lfp_timestamps_edges, labels, pos_timestamps, is_discrete=True)\n",
    "    \n",
    "     # Get binned position data for this flight\n",
    "    flight_pos = binned_pos[timebin_labels > 0]\n",
    "\n",
    "    # Adjust valid_phase_labels to match timebin_labels\n",
    "    adjusted_phase_labels = label_timebins(lfp_timestamps_edges, valid_phase_labels, pos_timestamps, is_discrete=True)\n",
    "    flight_phases = adjusted_phase_labels[timebin_labels > 0]\n",
    "    \n",
    "####### Current analysis task: marking whether current x is less than or greater than x=0\n",
    "\n",
    "    pos_flight_data = np.column_stack((\n",
    "        np.full(len(flight_pos), flight_count),\n",
    "        np.full(len(flight_pos), left_or_right(flight_pos[:,0])),\n",
    "        flight_pos,\n",
    "        flight_phases\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFP extraction and downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of lfp_data_1: <class 'numpy.ndarray'>, Shape of lfp_data_1: (192, 17222917)\n",
      "Type of lfp_data_2: <class 'numpy.ndarray'>, Shape of lfp_data_2: (192, 17222917)\n",
      "Number of channels per array: 192\n",
      "LFP combined shape: (172230, 384)\n",
      "Saving LFP data to cache...\n"
     ]
    }
   ],
   "source": [
    "lfp_bat_combined = extract_and_downsample_lfp_data(lfp_mat) #uses scipy decimate to downsample LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFPs = filter_data(lfp_bat_combined, 1, fs=25, filt_type='high', use_hilbert=True) \n",
    "LFPs = LFPs[lfp_indices] # mask for non-negativity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to get flightLFP for a specific cluster (get_flightLFP does so for specific cluster)\n",
    "\n",
    "flight_count = 0\n",
    "for flight in session.get_flights_by_cluster([3]):\n",
    "    flight_count+=1\n",
    "    flight_bool_phase_labels, phase_labels, _ = get_flight_boolean_array(session,flight_count)\n",
    "    \n",
    "    labels = flight_bool[pos_mask]\n",
    "    valid_phase_labels = phase_labels[pos_mask]\n",
    "    \n",
    "    timebin_labels = label_timebins(lfp_timestamps_edges, labels, pos_timestamps, is_discrete=True)\n",
    "\n",
    "    flight_lfp = LFPs[timebin_labels >0] # mark LFP points which mask to specific flight in cluster\n",
    "    \n",
    "     # Adjust valid_phase_labels to match timebin_labels\n",
    "    adjusted_phase_labels = label_timebins(lfp_timestamps_edges, valid_phase_labels, pos_timestamps, is_discrete=True)\n",
    "    flight_phases = adjusted_phase_labels[timebin_labels > 0]\n",
    "    \n",
    "    # Create flight data for all timebins of this flight\n",
    "    lfp_flight_data = np.column_stack((\n",
    "        np.full(len(flight_lfp), flight_count),\n",
    "        flight_phases,\n",
    "        flight_lfp\n",
    "    ))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now have our processed LFP. `LFPs` contains the filtered and (Hilbert) transformed LFP data for all of the valid `binned_pos` entries. However, we are mainly interested in the bat flights, which are just a *fraction* of the total of `binned_pos`. To filter out the non-flight entries from the LFP, we will apply a similar filtering method as we did in `get_flightID` with a `get_flightLFP` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training TIMBRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract left/right labels from pos_flight_data\n",
    "# Assuming the second column contains \"left\"/\"right\"/\"0\"\n",
    "pos_labels = pos_flight_data[:, 1]  # Second column\n",
    "label_mapping = {\"left\": 0, \"right\": 1}\n",
    "\n",
    "# Map the labels to integers\n",
    "Y = np.array([label_mapping[label] for label in pos_labels if label != \"0\"])  # Exclude \"0\"\n",
    "\n",
    "# Extract the LFP data corresponding to non-\"0\" labels\n",
    "X = lfp_flight_data[pos_labels != \"0\", :]  # Use rows where the labels aren't \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split indices into training and testing sets\n",
    "inds_train, inds_test = train_test_split(np.arange(len(X)), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TIMBRE from TIMBRE\n",
    "# Parameters for TIMBRE\n",
    "hidden_nodes = 10\n",
    "learn_rate = 0.001\n",
    "is_categorical = True\n",
    "\n",
    "# Call TIMBRE\n",
    "model, fitted_model, test_acc = TIMBRE(\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    inds_test=inds_test,\n",
    "    inds_train=inds_train,\n",
    "    hidden_nodes=hidden_nodes,\n",
    "    learn_rate=learn_rate,\n",
    "    is_categorical=is_categorical,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
